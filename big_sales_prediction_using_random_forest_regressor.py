# -*- coding: utf-8 -*-
"""Big Sales Prediction using Random Forest Regressor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KDcgxmTOGnX_q1QTuf8AKar1BnJUBUgH

**Big Sales Prediction using Random Forest Random Forest Regressor**

Get Understanding about Data set

There are 12 variable in dataset
1.Item_Identifier
2.Item_Weight
3.Item_Fat_Content
4.Item_Visibility
5.Item_Type
6.Item_MRP
7.Outlet_Identifier
8.Outlet_Establishment_year
9.Outer_Size
10.Outer_Size
11.Outlet_Type
12.Item_Outlet_Sales

**Import Library**
"""

import pandas as pd

import numpy as np

"""**Import CSV as DataFrame**

Use URL of file directly
"""

df = pd.read_csv('https://github.com/YBI-Foundation/Dataset/raw/main/Big%20Sales%20Data.csv')

"""you can use local file path in jupyter Notebook
or
use file path after uploading file in Google Colab Notebook

**Get the first Five Rows of Dataframe**
"""

df.head()

df.info()

"""**Get Column Names**"""

df.columns

"""**Get the Summary Statistics**"""

df.describe()

"""**Get Missing values Complete**"""

df['Item_Weight'].fillna(df.groupby(['Item_Type']) ['Item_Weight'].transform('mean'), inplace=True)

df.info()

df.describe()

import seaborn as sns
sns.pairplot(df)

"""**Get Categories and Counts of categorical Variables**"""

df[['Item_Identifier']].value_counts()

df[['Item_Fat_Content']].value_counts()

df.replace({'Item_Fat_Content': {'LF': 'Low Fat','reg':'Regular', 'low fat':'Low Fat'}}, inplace=True)

df[['Item_Fat_Content']].value_counts()

df.replace({'Item_Fat_Content': {'Low Fat': 0,'Regular' : 1}}, inplace=True)

df[['Item_Type']].value_counts()

df.replace({'Item_Type':{'Fruits and Vegetables':0,'Snack Foods':0,'Household':1,
                         'Frozen Foods' : 0,'Dairy' : 0,'Baking Goods' : 0,
                         'Canned' : 0,'Health and Hygiene' : 1,
                         'Meat' : 0,'Soft Drinks' : 0, 'Breads' : 0, 'Hard Drinks' : 0,
                         'others' : 2,'Starchy Foods' : 0,'Breakfast' : 0, 'Seafood' : 0
                         }},inplace=True)

df[['Item_Type']].value_counts()

df[['Outlet_Identifier']].value_counts()

df.replace({'Outlet_Identifier':{'OUT027': 0,'OUT013':1,
                                 'OUT049' : 2,'OUT046' : 3, 'OUT035' : 4,
                                  'OUT017' : 7, 'OUT010' : 8, 'OUT019' : 9,
                                  }})

df[['Outlet_Identifier']].value_counts()

df[['Outlet_Size']].value_counts()

df.replace({'Outlet_Size': {'Small' : 0,'Medium' : 1, 'High': 2}},inplace=True)

df[['Outlet_Size']].value_counts()

df[['Outlet_Location_Type']].value_counts()

df.replace({'Outlet_Location_Type': {'Tier 1' : 0,'Tier 2' : 1, 'Tier 3' : 2}}, inplace=True)

df[['Outlet_Location_Type']].value_counts()

df[['Outlet_Type']].value_counts()

df.replace({'Outlet_Type': {'Grocery Store': 0,'Supermarket Type1': 1,'Supermarket Type2': 2, 'Supermarket Type3': 3}}, inplace=True)

df[['Outlet_Type']].value_counts()

df.head()

df.info()

"""**Get Shape of DataFrame**"""

df.shape

"""**Define y(dependent or label or target variable ) and X(independent or feature or attribute variable )**"""

y = df['Item_Outlet_Sales']

y.shape

y

x = df[['Item_Weight','Item_Fat_Content', 'Item_Visibility','Item_Type', 'Item_MRP', 'Outlet_Identifier',
        'Outlet_Establishment_Year', 'Outlet_Size', 'Outlet_Location_Type',
        'Outlet_Type']]

"""or use.drop function to define X"""

X = df.drop(['Item_Identifier', 'Item_Outlet_Sales'], axis=1)

X.shape

X

"""**Get X Variables Standardized**

Standardization of datasets is a common requirement for many machine learning estimators implemented in scikit-learn; they might behave badly if the individual features do not more or less look like standard normally distributed data: Gaussian with zero mean and unit variance.
"""

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()

X_std = df[['Item_Weight', 'Item_Visibility', 'Item_MRP', 'Outlet_Establishment_Year']]

X_std = sc.fit_transform(X_std)

X_std

x[['Item_Weight', 'Item_Visibility', 'Item_MRP', 'Outlet_Establishment_Year']] = pd.DataFrame(X_std, columns=[['Item_Weight', 'Item_Visibility','Item_MRP', 'Outlet_Establishment_Year']])

X

"""**Get Train Test Split**"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.1, random_state=2529)

X_train.shape, X_test.shape, y_train.shape, y_test.shape

"""**Get Model Train**"""

from sklearn.ensemble import RandomForestRegressor

rfr = RandomForestRegressor(random_state=2529)

y_train = y_train.astype(str)

X_train = pd.get_dummies(X_train)

X_test = X_test.reindex(columns = X_train.columns, fill_value=0)

rfr.fit(X_train,y_train)

"""**Get Model Prediction**"""

y_pred = rfr.predict(X_test)

y_pred.shape

y_pred

"""**Get Model Evaluation**"""

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

mean_squared_error(y_test,y_pred)

mean_absolute_error(y_test, y_pred)

r2_score(y_test, y_pred)

"""**Get Visualization of Actual Vs Predicted Result**"""

import matplotlib.pyplot as plt
plt.scatter(y_test, y_pred)
plt.xlabel("Actual Prices")
plt.ylabel ("Predicted Prices")
plt.title("Actual Price vs Preicted Price")
plt.show()